{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing The Data\n",
    "\n",
    "#### Finding Number of images in Each Set\n",
    "Lets check how many images we have for each class in train and test sets.\n",
    "\n",
    "#### Normalization\n",
    "\n",
    "In order to speedup the training time we can devide the image matrices by 255 to map them to the range of [0,1]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing, metrics\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "# A function to plot images\n",
    "def show_image(img):\n",
    "    image = img.reshape((28, 28))\n",
    "    plt.imshow(image, 'gray')\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "# Reading The Train Set\n",
    "train_images_file = open('train-images.idx3-ubyte', 'rb')\n",
    "train_images_file.seek(4)\n",
    "num_of_train_images = int.from_bytes(train_images_file.read(4), 'big')\n",
    "train_images_file.seek(16)\n",
    "\n",
    "train_labels_file = open('train-labels.idx1-ubyte', 'rb')\n",
    "train_labels_file.seek(8)\n",
    "\n",
    "train_images, train_labels = [], []\n",
    "for n in range(num_of_train_images):\n",
    "    image = np.zeros((784, 1))\n",
    "    for i in range(784):\n",
    "        image[i, 0] = int.from_bytes(train_images_file.read(1), 'big') / 256\n",
    "    image = np.array(image).reshape((28, 28, 1))\n",
    "    train_images.append(image)\n",
    "    label_value = int.from_bytes(train_labels_file.read(1), 'big')\n",
    "    label = np.zeros((10, 1))\n",
    "    label[label_value, 0] = 1\n",
    "    train_labels.append(label)\n",
    "    \n",
    "    # train_set.append((aimage, label))\n",
    "\n",
    "\n",
    "# Reading The Test Set\n",
    "test_images_file = open('t10k-images.idx3-ubyte', 'rb')\n",
    "test_images_file.seek(4)\n",
    "\n",
    "test_labels_file = open('t10k-labels.idx1-ubyte', 'rb')\n",
    "test_labels_file.seek(8)\n",
    "\n",
    "num_of_test_images = int.from_bytes(test_images_file.read(4), 'big')\n",
    "test_images_file.seek(16)\n",
    "\n",
    "test_images, test_labels = [], []\n",
    "for n in range(num_of_test_images):\n",
    "    image = np.zeros((784, 1))\n",
    "    for i in range(784):\n",
    "        image[i] = int.from_bytes(test_images_file.read(1), 'big') / 256\n",
    "    image = np.array(image).reshape((28, 28, 1))\n",
    "    test_images.append(image)\n",
    "    label_value = int.from_bytes(test_labels_file.read(1), 'big')\n",
    "    label = np.zeros((10, 1))\n",
    "    label[label_value, 0] = 1\n",
    "    test_labels.append(label)\n",
    "\n",
    "\n",
    "# Plotting an image\n",
    "show_image(train_images[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert to numpy array\n",
    "As we need numpy array to implement LeNet-5 using numpy, we need to transfer array lists to numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = np.array(train_images)\n",
    "train_labels = np.array(train_labels)\n",
    "test_images = np.array(test_images)\n",
    "test_labels = np.array(test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shuffle the Image and Labels Matrices\n",
    "\n",
    "We should write a shuffle function to perform it on the data because we need it later in backpropagation process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m All tests passed.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import shuffle\n",
    "import time\n",
    "\n",
    "def shuffle_together(x, y):\n",
    "  return shuffle(x, y, random_state=int(time.time()))\n",
    "\n",
    "train_images, train_labels = shuffle_together(train_images, train_labels)\n",
    "test_images, test_labels = shuffle_together(test_images, test_labels)\n",
    "# train_images = train_images.reshape((train_images.shape[0], train_images.shape[1]))\n",
    "# test_images = test_images.reshape((test_images.shape[0], test_images.shape[1]))\n",
    "train_labels = train_labels.reshape((train_labels.shape[0], train_labels.shape[1]))\n",
    "test_labels = test_labels.reshape((test_labels.shape[0], test_labels.shape[1]))\n",
    "\n",
    "assert train_images.shape == (60000, 28, 28, 1)\n",
    "assert train_labels.shape == (60000, 10)\n",
    "assert test_images.shape == (10000, 28, 28, 1)\n",
    "assert test_labels.shape == (10000, 10)\n",
    "\n",
    "print(\"\\033[92m All tests passed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing Convolutional Neural Network (CNN)\n",
    "LeNet-5 Architecture\n",
    "1. Input Layer\n",
    "    * Input Size: 32 × 32 grayscale image (1 channel)\n",
    "2. C1 - First Convolutional Layer\n",
    "    * Number of Filters: 6\n",
    "    * Filter Size: 5 × 5\n",
    "    * Stride: 1\n",
    "    * Padding: 2 (to maintain the input size as 32 × 32)\n",
    "    * Output Size: 28 × 28 × 6 (28 x 28 spatial dimensions with 6 channels)\n",
    "3. S2 - First Subsampling (Pooling) Layer\n",
    "    * Type: Average Pooling\n",
    "    * Filter Size: 2 × 2\n",
    "    * Stride: 2\n",
    "    * Output Size: 14 × 14 ×6\n",
    "4. C3 - Second Convolutional Layer\n",
    "    * Number of Filters: 16\n",
    "    * Filter Size: 5 × 5\n",
    "    * Stride: 1\n",
    "    * Padding: 0\n",
    "    * Output Size: 10 × 10 × 16\n",
    "5. S4 - Second Subsampling (Pooling) Layer\n",
    "    * Type: Average Pooling\n",
    "    * Filter Size: 2 × 2\n",
    "    * Stride: 2\n",
    "    * Output Size: 5 × 5 × 16\n",
    "6. C5 - Third Convolutional Layer\n",
    "    * Number of Filters: 120\n",
    "    * Filter Size: 5 × 5\n",
    "    * Stride: 1\n",
    "    * Padding: 0\n",
    "    * Output Size: 1 × 1 × 120\n",
    "7. F6 - Fully Connected Layer\n",
    "    * Number of Neurons: 84\n",
    "    * Activation: Relu Or Tanh\n",
    "8. Output Layer\n",
    "    * Number of Neurons: 10 (for digit classification from 0 to 9)\n",
    "    * Activation: Softmax or Sigmoid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conv layer\n",
    "At first, I implement Conv layer's forward and backward prop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv():\n",
    "    weight = None\n",
    "    bias = None\n",
    "    nc = None\n",
    "    nc_prev = None\n",
    "    filter_size = None\n",
    "    stride = None\n",
    "    pad = None\n",
    "    learn_rate = None\n",
    "    img = None\n",
    "\n",
    "    def __init__(self, nc = 0, filter_size = 0, stride = 1, pad = 0, learn_rate = 0.01, nc_prev = 1):\n",
    "        self.nc = nc\n",
    "        self.filter_size = filter_size\n",
    "        self.bias = np.random.randn(1, 1, 1, nc) * (1 / 1500)\n",
    "        self.weight = np.random.randn(filter_size, filter_size, nc_prev, nc) * (nc_prev / 1500)\n",
    "        self.stride = stride\n",
    "        self.pad = pad\n",
    "        self.learn_rate = learn_rate\n",
    "        self.nc_prev = nc_prev\n",
    "\n",
    "    def forward(self, img):\n",
    "        \n",
    "        self.img = np.pad(img,((0,0),(self.pad,self.pad),(self.pad,self.pad),(0,0)))\n",
    "        \n",
    "        (layer, nh_prev, nw_prev, nc_prev) = img.shape\n",
    "        # print(f'weight shape = {self.weight.shape}, bias shape = {self.bias.shape}')\n",
    "        # print(\"====================================\")\n",
    "\n",
    "        nh = int((nh_prev + 2 * self.pad - self.filter_size) / self.stride) + 1\n",
    "        nw = int((nw_prev + 2 * self.pad - self.filter_size) / self.stride) + 1\n",
    "\n",
    "        Z = np.zeros((layer, nh, nw, self.nc))\\\n",
    "\n",
    "        for i in range(layer):\n",
    "            current_img = self.img[i]\n",
    "            for h in range(nh):\n",
    "                vertical_start = self.stride * h\n",
    "                vertical_end = vertical_start + self.filter_size\n",
    "                for w in range(nw):\n",
    "                    horizontal_start = self.stride * w\n",
    "                    horizontal_end = horizontal_start + self.filter_size\n",
    "                    for c in range(self.nc):\n",
    "                        slice_of_img = current_img[vertical_start:vertical_end, horizontal_start:horizontal_end, :]\n",
    "                        weights = self.weight[:, :, :, c]\n",
    "                        biases = self.bias[:, :, :, c]\n",
    "                        z = np.multiply(slice_of_img, weights)\n",
    "                        z = np.sum(z)\n",
    "                        biases = np.squeeze(biases)\n",
    "                        z += biases\n",
    "                        # print(f'image shape: {slice_of_img.shape}, weight shape: {weights.shape}, bias = {biases}, bias shape: {biases.shape}, z = {z} ,z shape: {z.shape}')\n",
    "                        Z[i, h, w, c] = z\n",
    "        return Z\n",
    "    \n",
    "    def backward(self, dZ):\n",
    "        # print(f'pad = {self.pad}')\n",
    "        (layer, nh, nw, nc) = dZ.shape\n",
    "        dimg = np.zeros(self.img.shape)\n",
    "        dweight = np.zeros(self.weight.shape)\n",
    "        dbias = np.zeros(self.bias.shape)\n",
    "\n",
    "        img_pad = np.pad(self.img, ((0, 0), (self.pad, self.pad), (self.pad, self.pad), (0, 0)))\n",
    "        dimg_pad = np.pad(dimg, ((0, 0), (self.pad, self.pad), (self.pad, self.pad), (0, 0)))\n",
    "        for i in range(layer):\n",
    "            current_img_pad = img_pad[i]\n",
    "            current_dimg_pad = dimg_pad[i]\n",
    "            for h in range(nh):\n",
    "                for w in range(nw):\n",
    "                    for c in range(nc):\n",
    "                        vertical_start = self.stride * h\n",
    "                        vertical_end = vertical_start + self.filter_size\n",
    "                        horizontal_start = self.stride * w\n",
    "                        horizontal_end = horizontal_start + self.filter_size\n",
    "\n",
    "                        slice_of_img = current_img_pad[vertical_start:vertical_end, horizontal_start:horizontal_end, :]\n",
    "                        \n",
    "                        current_dimg_pad[vertical_start:vertical_end, horizontal_start:horizontal_end, :] += self.weight[:,:,:,c] * dZ[i, h, w, c]\n",
    "                        dweight[:,:,:,c] += slice_of_img * dZ[i, h, w, c] * self.learn_rate\n",
    "                        dbias[:,:,:,c] += dZ[i, h, w, c] * self.learn_rate\n",
    "            print(f'dimg_pad shape = {current_dimg_pad[self.pad:-self.pad, self.pad:-self.pad, :].shape}, dimag shape = {dimg[i, :, :, :].shape}')\n",
    "            dimg[i, :, :, :] = current_dimg_pad[self.pad:-self.pad, self.pad:-self.pad, :]\n",
    "        \n",
    "        self.weight -= dweight * self.learn_rate\n",
    "        self.bias -= dbias * self.learn_rate\n",
    "        return dimg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pooling layer\n",
    "Now, it's time to implement pooling layer\n",
    "\n",
    "You should give every implementations\n",
    "\n",
    "nc = number of channels\n",
    "\n",
    "you should give your ordered mode (max pooling or average pooling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Pool():\n",
    "    stride = None\n",
    "    filter_size = None\n",
    "    nc = None\n",
    "    img = None\n",
    "    pad = None\n",
    "    mode = None\n",
    "\n",
    "    def __init__(self, stride = 1, filter_size = 0, nc = 1, pad = 0, mode = \"max\"):\n",
    "        self.stride = stride\n",
    "        self.filter_size = filter_size\n",
    "        self.nc = nc\n",
    "        self.pad = pad\n",
    "        self.mode = mode.lower()\n",
    "\n",
    "    def forward(self, img):\n",
    "        \n",
    "        self.img = img\n",
    "        \n",
    "        (layer, nh_prev, nw_prev, nc_prev) = img.shape\n",
    "\n",
    "        nh = int((nh_prev + 2 * self.pad - self.filter_size) / self.stride) + 1\n",
    "        nw = int((nw_prev + 2 * self.pad - self.filter_size) / self.stride) + 1\n",
    "\n",
    "        Z = np.zeros((layer, nh, nw, self.nc))\n",
    "\n",
    "        for i in range(layer):\n",
    "            current_img = img[i]\n",
    "            for h in range(nh):\n",
    "                vertical_start = self.stride * h\n",
    "                vertical_end = vertical_start + self.filter_size\n",
    "                for w in range(nw):\n",
    "                    horizontal_start = self.stride * w\n",
    "                    horizontal_end = horizontal_start + self.filter_size\n",
    "                    for c in range(self.nc):\n",
    "                        slice_of_img = current_img[vertical_start:vertical_end, horizontal_start:horizontal_end, :]\n",
    "                        if self.mode == 'avrage':\n",
    "                            Z[i, h, w, c] = np.mean(slice_of_img)\n",
    "                        else:\n",
    "                            Z[i, h, w, c] = np.max(slice_of_img)\n",
    "\n",
    "        return Z\n",
    "    \n",
    "    def backward(self, dz):\n",
    "        (layer, nh, nw, nc) = dz.shape\n",
    "        dimg = np.zeros(self.img.shape)\n",
    "        for i in range(layer):\n",
    "            current_img = self.img[i]\n",
    "            for h in range(nh):\n",
    "                vertical_start = self.stride * h\n",
    "                vertical_end = vertical_start + self.filter_size\n",
    "                for w in range(nw):\n",
    "                    horizontal_start = self.stride * w\n",
    "                    horizontal_end = horizontal_start + self.filter_size\n",
    "                    for c in range(nc):\n",
    "                        slice_of_img = current_img[vertical_start:vertical_end, horizontal_start:horizontal_end, :]\n",
    "                        if self.mode == 'avrage':\n",
    "                            dimg[i, vertical_start:vertical_end, horizontal_start:horizontal_end, :] += dz[i, h, w, c] / np.prod((self.filter_size, self.filter_size))\n",
    "                        else:\n",
    "                            mask = slice_of_img == np.max(slice_of_img)\n",
    "                            dimg[i, vertical_start:vertical_end, horizontal_start:horizontal_end, :] += mask * dz[i, h, w, c]\n",
    "        return dimg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fully Connected layes\n",
    "Here we implemented fully connected layer\n",
    "\n",
    "neurons = number of neurons in this layer\n",
    "\n",
    "weights and bias will implement automatically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FC():\n",
    "\n",
    "    neurons = None\n",
    "    inputNeurons = None\n",
    "    weights = None\n",
    "    bias = None\n",
    "    learn_rate = None\n",
    "    img = None\n",
    "    def __init__(self, learn_rate = 0.01, neurons = 1, inputNeurons = 1) -> None:\n",
    "        self.neurons = neurons\n",
    "        self.learn_rate = learn_rate\n",
    "        self.weights = np.random.randn(inputNeurons, neurons) * (1 / 1500)\n",
    "        self.bias = np.zeros(neurons)\n",
    "        self.inputNeurons = inputNeurons\n",
    "\n",
    "    def forward(self, img):\n",
    "        self.img = img\n",
    "        # print(f'img shape: {img.shape}, weights shape: {self.weights.shape}, bias shape: {self.bias.shape}')\n",
    "        Z = self.img @ self.weights + self.bias\n",
    "        return Z\n",
    "    \n",
    "    def backward(self, dz):\n",
    "        dimg = dz @ self.weights.T\n",
    "        dw = self.img.T @ dz\n",
    "        # print(f'weight shape: {self.weights.shape}, dw shape: {dw.shape}, img shape: {self.img.shape}, dz shape: {dz.shape}')\n",
    "        self.weights -= dw * self.learn_rate\n",
    "        self.bias -= np.sum(dz, axis=0) * self.learn_rate\n",
    "        return dimg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Flatten():\n",
    "    cache_X = None\n",
    "\n",
    "    def forward(self, X):\n",
    "        # X is of shape (batch_size, height, width, in_nchannel)\n",
    "        # output is of shape (batch_size, -1)\n",
    "        self.cache_X = X\n",
    "        return X.reshape((len(X), -1))\n",
    "\n",
    "    def backward(self, grad_in):\n",
    "        return grad_in.reshape(self.cache_X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReLU():\n",
    "\n",
    "    cache_X = None\n",
    "    def forward(self, X):\n",
    "        self.cache_X = X\n",
    "        return np.maximum(X, 0)\n",
    "\n",
    "    def backward(self, grad_in):\n",
    "        dX = grad_in.copy()\n",
    "        dX[self.cache_X <= 0] = 0\n",
    "        return dX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sigmoid():\n",
    "\n",
    "    chache_X = None\n",
    "    def forward(self, X):\n",
    "        self.chache_X = X\n",
    "        return 1 / (1 + np.exp(-X))\n",
    "    def backward(self, grad, X = None):\n",
    "    \n",
    "        s = 1/(1+np.exp(-self.chache_X))\n",
    "        dX = grad * s * (1-s)\n",
    "        return dX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tanh():\n",
    "\n",
    "    cached_X = None\n",
    "    def forward(self, x):\n",
    "        self.cached_X = np.tanh(x)\n",
    "        return self.cached_X\n",
    "    \n",
    "    def backward(self, dout, X = None):\n",
    "        # Derivative of tanh is 1 - tanh^2(x)\n",
    "        dinput = dout * (1 - self.cached_X ** 2)\n",
    "        return dinput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(X):\n",
    "    # print(f'type X = {type(X)}')\n",
    "    e_x = np.exp(X - np.max(X, axis=-1, keepdims=True))\n",
    "    probs = e_x / e_x.sum(axis=-1, keepdims=True)\n",
    "        # return preprocessing.normalize(probs + epsilon, norm='l1')\n",
    "    return probs\n",
    "\n",
    "class Softmax():\n",
    "\n",
    "    cache_grad = None\n",
    "    cache_X = None\n",
    "    \n",
    "    def forward(self, X, y):\n",
    "        # X, y and y_hat are of shape (batch_size, in_dim)\n",
    "        self.cache_X = X\n",
    "        m = len(X)\n",
    "        # print(f'type X: {type(X)}')\n",
    "        y_hat = softmax(X)\n",
    "        loss = (-1 / m) * np.log(y_hat[y == 1]).sum()\n",
    "        self.cache_grad = (y_hat - y) / m\n",
    "        return y_hat, loss\n",
    "\n",
    "    def backward(self, grad):\n",
    "        # print(self.cache_grad, self.cache_X)\n",
    "        return self.cache_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model():\n",
    "\n",
    "    layers = []\n",
    "\n",
    "    def implementConv(self,  nc = 0, filter_size = 0, stride = 1, pad = 0, learn_rate = 0.01, nc_prev = 1):\n",
    "        self.layers.append(Conv(nc=nc, filter_size=filter_size, stride=stride, pad=pad, learn_rate=learn_rate, nc_prev=nc_prev))\n",
    "    \n",
    "    def implementPooling(self, stride = 1, filter_size = 0, nc = 1, pad = 0, mode = \"max\"):\n",
    "        self.layers.append(Pool(stride, filter_size, nc, pad, mode))\n",
    "\n",
    "    def implementFullyConnected(self, learn_rate = 0.01, neurons = 1, inputNeurons = 1):\n",
    "        self.layers.append(FC(learn_rate, neurons, inputNeurons))\n",
    "\n",
    "    def setFlatten(self):\n",
    "        self.layers.append(Flatten())\n",
    "\n",
    "    def setRelu(self):\n",
    "        self.layers.append(ReLU())\n",
    "\n",
    "    def setTanh(self):\n",
    "        self.layers.append(Tanh())\n",
    "    \n",
    "    def setSigmoid(self):\n",
    "        self.layers.append(Sigmoid())\n",
    "\n",
    "    def setSoftmax(self):\n",
    "        self.layers.append(Softmax())\n",
    "\n",
    "    def forward(self, X, Y = None):\n",
    "        for layer in self.layers[: -1]:\n",
    "            X = layer.forward(X)\n",
    "        y_hat, loss = self.layers[-1].forward(X, Y)\n",
    "        return y_hat, loss\n",
    "    \n",
    "    def backward(self):\n",
    "        grad = 1\n",
    "        for layer in reversed(self.layers):\n",
    "            grad = layer.backward(grad)\n",
    "        return grad\n",
    "    \n",
    "    def fit(self, X_train, y_train, X_validate, y_validate, epochs=1, batch_size=32):\n",
    "        n_sample = len(X_train)\n",
    "        n_batch = (n_sample - 1) // batch_size + 1\n",
    "        y_pred = np.zeros_like(y_train)\n",
    "        for epoch in range(epochs):\n",
    "            print(f\"Epoch {epoch+1} ================\")\n",
    "            with tqdm(total = n_batch) as t:\n",
    "                tot_loss = tot_acc = 0\n",
    "                for i in range(n_batch):\n",
    "                    batch = range(batch_size * i, min(batch_size * (i + 1), n_sample))\n",
    "                    y_hat, loss = self.forward(X_train[batch], y_train[batch])\n",
    "                    acc = (1 / len(batch)) * np.sum(np.argmax(y_hat) == np.argmax(y_train[batch]))\n",
    "                    y_pred[batch] = y_hat\n",
    "                    grad = self.backward()\n",
    "                    tot_loss += loss\n",
    "                    tot_acc += acc\n",
    "                    if (i + 1) % 32 == 0 or i + 1 == n_batch:\n",
    "                        t.set_postfix({\n",
    "                            'avg_loss': tot_loss / (i + 1),\n",
    "                            'avg_accuracy': tot_acc / (i + 1),\n",
    "                            'max_abs_gradient': np.max(abs(grad))\n",
    "                        })\n",
    "                        cur_n_batch = i % 32 + 1\n",
    "                        t.update(cur_n_batch)\n",
    "            print(\"Validation:\")\n",
    "            val_y_hat, val_loss = self.evaluate(X_validate, y_validate)\n",
    "            print('loss: ', val_loss)\n",
    "            print(\n",
    "                metrics.classification_report(np.argmax(val_y_hat, axis=-1),\n",
    "                                              np.argmax(y_validate)))\n",
    "            \n",
    "    def predict(self, X, batch_size=32):\n",
    "        y_pred = []\n",
    "        n_sample = len(X)\n",
    "        n_batch = (n_sample - 1) // batch_size + 1\n",
    "        for i in tqdm(range(n_batch)):\n",
    "            batch = range(batch_size * i, min(batch_size * (i + 1), n_sample))\n",
    "            y_hat = self.forward(X[batch])\n",
    "            y_pred.append(y_hat)\n",
    "        return np.concatenate(y_pred)\n",
    "\n",
    "    def evaluate(self, X, y, batch_size=32):\n",
    "        y_pred = []\n",
    "        n_sample = len(X)\n",
    "        n_batch = (n_sample - 1) // batch_size + 1\n",
    "        tot_loss = 0\n",
    "        for i in tqdm(range(n_batch)):\n",
    "            batch = range(batch_size * i, min(batch_size * (i + 1), n_sample))\n",
    "            y_hat, loss = self.forward(X[batch], y[batch])\n",
    "            y_pred.append(y_hat)\n",
    "            tot_loss += loss\n",
    "        return np.concatenate(y_pred), tot_loss / n_batch\n",
    "\n",
    "    def get_weights(self):\n",
    "        weights = []\n",
    "        for layer in self.layers:\n",
    "            if hasattr(layer, 'W'):\n",
    "                weights.append(layer.W)\n",
    "            if hasattr(layer, 'b'):\n",
    "                weights.append(layer.b)\n",
    "        return weights\n",
    "\n",
    "    def set_weights(self, weights):\n",
    "        # careful of not copying by reference\n",
    "        weight_iter = iter(weights)\n",
    "        for layer in self.layers:\n",
    "            if hasattr(layer, 'W'):\n",
    "                layer.W = np.array(next(weight_iter))\n",
    "            if hasattr(layer, 'b'):\n",
    "                layer.b = np.array(next(weight_iter))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 ================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1875 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dimg_pad shape = (0, 0, 16), dimag shape = (5, 5, 16)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not broadcast input array from shape (0,0,16) into shape (5,5,16)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[79], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m model\u001b[38;5;241m.\u001b[39mimplementFullyConnected(neurons\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, learn_rate\u001b[38;5;241m=\u001b[39mlearn_rate, inputNeurons\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m84\u001b[39m)\n\u001b[1;32m     12\u001b[0m model\u001b[38;5;241m.\u001b[39msetSoftmax()\n\u001b[0;32m---> 13\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_images\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_labels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_images\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_labels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[78], line 54\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, X_train, y_train, X_validate, y_validate, epochs, batch_size)\u001b[0m\n\u001b[1;32m     52\u001b[0m acc \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(batch)) \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39msum(np\u001b[38;5;241m.\u001b[39margmax(y_hat) \u001b[38;5;241m==\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(y_train[batch]))\n\u001b[1;32m     53\u001b[0m y_pred[batch] \u001b[38;5;241m=\u001b[39m y_hat\n\u001b[0;32m---> 54\u001b[0m grad \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m tot_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\n\u001b[1;32m     56\u001b[0m tot_acc \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m acc\n",
      "Cell \u001b[0;32mIn[78], line 38\u001b[0m, in \u001b[0;36mModel.backward\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     36\u001b[0m grad \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mreversed\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers):\n\u001b[0;32m---> 38\u001b[0m     grad \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrad\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m grad\n",
      "Cell \u001b[0;32mIn[70], line 81\u001b[0m, in \u001b[0;36mConv.backward\u001b[0;34m(self, dZ)\u001b[0m\n\u001b[1;32m     79\u001b[0m                 dbias[:,:,:,c] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m dZ[i, h, w, c] \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlearn_rate\n\u001b[1;32m     80\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdimg_pad shape = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcurrent_dimg_pad[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpad:\u001b[38;5;241m-\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpad,\u001b[38;5;250m \u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpad:\u001b[38;5;241m-\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpad,\u001b[38;5;250m \u001b[39m:]\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, dimag shape = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdimg[i,\u001b[38;5;250m \u001b[39m:,\u001b[38;5;250m \u001b[39m:,\u001b[38;5;250m \u001b[39m:]\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 81\u001b[0m     \u001b[43mdimg\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m current_dimg_pad[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpad:\u001b[38;5;241m-\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpad, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpad:\u001b[38;5;241m-\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpad, :]\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m dweight \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlearn_rate\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m dbias \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlearn_rate\n",
      "\u001b[0;31mValueError\u001b[0m: could not broadcast input array from shape (0,0,16) into shape (5,5,16)"
     ]
    }
   ],
   "source": [
    "learn_rate = 0.02\n",
    "model = Model()\n",
    "model.implementConv(nc=6, filter_size=5, learn_rate=learn_rate, pad=2)\n",
    "model.implementPooling(nc=6, filter_size=2, stride=2)\n",
    "model.implementConv(nc=16, nc_prev=6, filter_size=5, learn_rate=learn_rate)\n",
    "model.implementPooling(nc=16, filter_size=2, stride=2)\n",
    "model.implementConv(nc=120, filter_size=5, nc_prev=16, learn_rate=learn_rate)\n",
    "model.setFlatten()\n",
    "model.implementFullyConnected(neurons=84, learn_rate=learn_rate, inputNeurons=120)\n",
    "model.setRelu()\n",
    "model.implementFullyConnected(neurons=10, learn_rate=learn_rate, inputNeurons=84)\n",
    "model.setSoftmax()\n",
    "model.fit(train_images, train_labels, test_images, test_labels, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2\n",
      "3\n",
      "3\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
